{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jovyan/critical_feature_extraction\n"
     ]
    }
   ],
   "source": [
    "cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run __init__.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean the Data:\n",
    "1. Drop the Acc/Dist_ROC_1 feature because it is only producing 0's\n",
    "2. Drop all NaN values\n",
    "3. Create a DataFrame with:\n",
    "    - count *before* cleaning\n",
    "    - count *after* cleaning\n",
    "    - *difference* between the original and new count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make an empty dict\n",
    "count_diff = {}\n",
    "\n",
    "#create a list of the different tickers \n",
    "individuals = os.listdir(path = \"data/sandp500/individual_stocks_5yr/\")\n",
    "\n",
    "#iterate through all of the csv files\n",
    "for csv in individuals:\n",
    "    #only create paths with .csv included in the list\n",
    "    if '.csv' in csv:\n",
    "        #create a path with each csv\n",
    "        csv_path = \"data/sandp500/individual_stocks_5yr_TECHNICALS/\" + csv\n",
    "        #create a df with path\n",
    "        df = pd.read_csv(csv_path)\n",
    "        #find the original number of observations\n",
    "        orig_count = len(df.index)\n",
    "        try:\n",
    "            #clean the data by dropping the Acc/Dist_ROC_1 feature\n",
    "            df = df.drop('Acc/Dist_ROC_1', axis=1)\n",
    "            #drop all NaN values\n",
    "            df = df.dropna()\n",
    "            #save the cleaned df to csv in the individual_stocks_5yr_TECHNICALS_clean folder\n",
    "            df.to_csv(f\"data/sandp500/individual_stocks_5yr_TECHNICALS_clean/{csv}\")\n",
    "            #define the new count of the cleaned data \n",
    "            new_count = len(df.index)\n",
    "            #find the difference between the original count and the cleaned count\n",
    "            diff = orig_count - new_count\n",
    "            #add the difference, original_count and cleaned_count to the shape_diff dict\n",
    "            count_diff.update({f'{csv}':\n",
    "                               {'difference': diff, \n",
    "                               'original_count':orig_count, \n",
    "                               'cleaned_count':new_count}})\n",
    "        except:\n",
    "            print(f\"Technical cleaning failed on {csv}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a df from the shape_diff dictionary and transpose it\n",
    "obs_diff = pd.DataFrame(count_diff).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cleaned_count</th>\n",
       "      <th>difference</th>\n",
       "      <th>original_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AAL_data.csv</th>\n",
       "      <td>865</td>\n",
       "      <td>61</td>\n",
       "      <td>926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AGN_data.csv</th>\n",
       "      <td>903</td>\n",
       "      <td>71</td>\n",
       "      <td>974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ALLE_data.csv</th>\n",
       "      <td>869</td>\n",
       "      <td>71</td>\n",
       "      <td>940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AVGO_data.csv</th>\n",
       "      <td>326</td>\n",
       "      <td>61</td>\n",
       "      <td>387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BHF_data.csv</th>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BHGE_data.csv</th>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CCI_data.csv</th>\n",
       "      <td>598</td>\n",
       "      <td>71</td>\n",
       "      <td>669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CFG_data.csv</th>\n",
       "      <td>656</td>\n",
       "      <td>71</td>\n",
       "      <td>727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CHTR_data.csv</th>\n",
       "      <td>251</td>\n",
       "      <td>61</td>\n",
       "      <td>312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CSRA_data.csv</th>\n",
       "      <td>367</td>\n",
       "      <td>71</td>\n",
       "      <td>438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DXC_data.csv</th>\n",
       "      <td>31</td>\n",
       "      <td>71</td>\n",
       "      <td>102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EQIX_data.csv</th>\n",
       "      <td>582</td>\n",
       "      <td>61</td>\n",
       "      <td>643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EVHC_data.csv</th>\n",
       "      <td>103</td>\n",
       "      <td>71</td>\n",
       "      <td>174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FTI_data.csv</th>\n",
       "      <td>74</td>\n",
       "      <td>71</td>\n",
       "      <td>145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FTV_data.csv</th>\n",
       "      <td>221</td>\n",
       "      <td>73</td>\n",
       "      <td>294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HLT_data.csv</th>\n",
       "      <td>852</td>\n",
       "      <td>71</td>\n",
       "      <td>923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HPE_data.csv</th>\n",
       "      <td>387</td>\n",
       "      <td>71</td>\n",
       "      <td>458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ICE_data.csv</th>\n",
       "      <td>878</td>\n",
       "      <td>71</td>\n",
       "      <td>949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>INFO_data.csv</th>\n",
       "      <td>733</td>\n",
       "      <td>61</td>\n",
       "      <td>794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IRM_data.csv</th>\n",
       "      <td>575</td>\n",
       "      <td>71</td>\n",
       "      <td>646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>JCI_data.csv</th>\n",
       "      <td>618</td>\n",
       "      <td>71</td>\n",
       "      <td>689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KHC_data.csv</th>\n",
       "      <td>471</td>\n",
       "      <td>61</td>\n",
       "      <td>532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MDT_data.csv</th>\n",
       "      <td>571</td>\n",
       "      <td>71</td>\n",
       "      <td>642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MNST_data.csv</th>\n",
       "      <td>485</td>\n",
       "      <td>61</td>\n",
       "      <td>546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MYL_data.csv</th>\n",
       "      <td>558</td>\n",
       "      <td>61</td>\n",
       "      <td>619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NAVI_data.csv</th>\n",
       "      <td>776</td>\n",
       "      <td>61</td>\n",
       "      <td>837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NLSN_data.csv</th>\n",
       "      <td>421</td>\n",
       "      <td>71</td>\n",
       "      <td>492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PNR_data.csv</th>\n",
       "      <td>735</td>\n",
       "      <td>71</td>\n",
       "      <td>806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PRGO_data.csv</th>\n",
       "      <td>856</td>\n",
       "      <td>62</td>\n",
       "      <td>918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PYPL_data.csv</th>\n",
       "      <td>471</td>\n",
       "      <td>61</td>\n",
       "      <td>532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>QRVO_data.csv</th>\n",
       "      <td>597</td>\n",
       "      <td>61</td>\n",
       "      <td>658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ROP_data.csv</th>\n",
       "      <td>477</td>\n",
       "      <td>61</td>\n",
       "      <td>538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SYF_data.csv</th>\n",
       "      <td>694</td>\n",
       "      <td>71</td>\n",
       "      <td>765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>UA_data.csv</th>\n",
       "      <td>278</td>\n",
       "      <td>71</td>\n",
       "      <td>349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WBA_data.csv</th>\n",
       "      <td>598</td>\n",
       "      <td>61</td>\n",
       "      <td>659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WRK_data.csv</th>\n",
       "      <td>467</td>\n",
       "      <td>72</td>\n",
       "      <td>539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XL_data.csv</th>\n",
       "      <td>195</td>\n",
       "      <td>71</td>\n",
       "      <td>266</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               cleaned_count  difference  original_count\n",
       "AAL_data.csv             865          61             926\n",
       "AGN_data.csv             903          71             974\n",
       "ALLE_data.csv            869          71             940\n",
       "AVGO_data.csv            326          61             387\n",
       "BHF_data.csv               0          20              20\n",
       "BHGE_data.csv              0          28              28\n",
       "CCI_data.csv             598          71             669\n",
       "CFG_data.csv             656          71             727\n",
       "CHTR_data.csv            251          61             312\n",
       "CSRA_data.csv            367          71             438\n",
       "DXC_data.csv              31          71             102\n",
       "EQIX_data.csv            582          61             643\n",
       "EVHC_data.csv            103          71             174\n",
       "FTI_data.csv              74          71             145\n",
       "FTV_data.csv             221          73             294\n",
       "HLT_data.csv             852          71             923\n",
       "HPE_data.csv             387          71             458\n",
       "ICE_data.csv             878          71             949\n",
       "INFO_data.csv            733          61             794\n",
       "IRM_data.csv             575          71             646\n",
       "JCI_data.csv             618          71             689\n",
       "KHC_data.csv             471          61             532\n",
       "MDT_data.csv             571          71             642\n",
       "MNST_data.csv            485          61             546\n",
       "MYL_data.csv             558          61             619\n",
       "NAVI_data.csv            776          61             837\n",
       "NLSN_data.csv            421          71             492\n",
       "PNR_data.csv             735          71             806\n",
       "PRGO_data.csv            856          62             918\n",
       "PYPL_data.csv            471          61             532\n",
       "QRVO_data.csv            597          61             658\n",
       "ROP_data.csv             477          61             538\n",
       "SYF_data.csv             694          71             765\n",
       "UA_data.csv              278          71             349\n",
       "WBA_data.csv             598          61             659\n",
       "WRK_data.csv             467          72             539\n",
       "XL_data.csv              195          71             266"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#show only the tickers where the original_count is less than 1000\n",
    "obs_diff[obs_diff['original_count']<1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cleaned_count     37\n",
       "difference        37\n",
       "original_count    37\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#show how many tickers have less than 1000 observations \n",
    "obs_diff[obs_diff['original_count']<1000].count()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
